---
title: "Lab 6 ESS-330"
format: html
editor: visual
---

## Data Download

Here I downloaded and loaded in all the necessary packages.

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath(".."))
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
library(dplyr)
library(glmnet)
```

Now I have to download the CAMELS dataset and documentation PDF

```{r}
root  <- 'https://gdex.ucar.edu/dataset/camels/file'
```

```{r}
download.file(
  "https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf",
  destfile = here::here("data","camels_attributes_v2.0.pdf"),
  mode     = "wb"
)



```

After downloading the data, I had to create remote and local file paths for six CAMELS attribute text files, then I downloaded each one into my data folder. Then I read all the downloaded files into R as tibbles and performs a full outer join on gauge_id to combine them into a single dataset.

```{r}
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")

remote_files  <- glue('{root}/camels_{types}.txt')

local_files   <- glue('data/camels_{types}.txt')

walk2(remote_files, local_files, download.file, quiet = TRUE)

camels <- map(local_files, read_delim, show_col_types = FALSE) 

camels <- power_full_join(camels ,by = 'gauge_id')

camels <- camels %>% 
  filter(q_mean > 0) %>%                   # drop any zeros or negatives
  mutate(logQmean = log(q_mean))           # now every logQmean is finite

# then re‐do your splitting…
camels_split <- initial_split(camels, prop = 0.75, strata = logQmean)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)
camels_cv    <- vfold_cv(camels_train, v = 10, strata = logQmean)

```

## Question 1

Question 1: zero_q_freq represents the frequency of days with Q = 0 mm/day.

Here is the map that was provided to us in the lab instructions.

```{r}
library(ggthemes)
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

## Question 2

Question #2: Here are my 2 maps

```{r}

library(patchwork)
library(ggpubr)

# Map 1: colored by aridity
map_aridity <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity), size = 1.5) +
  scale_color_viridis_c(option = "magma", name = "Aridity\n(index)") +
  labs(
    title    = "CAMELS Sites: Aridity",
    x        = "Longitude",
    y        = "Latitude"
  ) +
  theme_map() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
  )

# Map 2: colored by mean precipitation
map_pmean <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = p_mean), size = 1.5) +
  scale_color_viridis_c(option = "plasma", name = expression(bar(P)~"(mm)")) +
  labs(
    title    = "CAMELS Sites: Mean Precipitation",
    x        = "Longitude",
    y        = "Latitude"
  ) +
  theme_map() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold")
  )

ggarrange(
  map_aridity + theme(legend.position = "bottom"),
  map_pmean   + theme(legend.position = "bottom"),
  ncol        = 2,
  font.label  = list(size = 14, face = "bold")
)
```

## Model Preparation

For the next part, I have to do some model preparation. The following code (up until Question #3) is provided for us in the lab, but I am copying it all down, along with the explanations, so I can follow along easier.

```{r}
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

As expected, there is a strong correlation between rainfall and mean flow, and an inverse correlation between aridity and rainfall. While both are high, we are going see if we can build a model to predict mean flow using aridity and rainfall.

We'll start by looking that the 3 dimensions (variables) of this data. We’ll start with a XY plot of aridity and rainfall.

```{r}
# Create a scatter plot of aridity vs rainfall
ggplot(camels, aes(x = aridity, y = p_mean)) +
  # Add points colored by mean flow
  geom_point(aes(color = q_mean)) +
  # Add a linear regression line
  geom_smooth(method = "lm", color = "red", linetype = 2) +
  # Apply the viridis color scale
  scale_color_viridis_c() +
  # Add a title, axis labels, and theme (w/ legend on the bottom)
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

So it looks like there is a relationship between rainfall, aridity, and rainfall but it looks like an exponential decay function and is certainly not linear.

To test a transformation, we can log transform the x and y axes using the scale_x_log10() and scale_y_log10() functions.

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  # Apply log transformations to the x and y axes
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

We can see a log-log relationship between aridity and rainfall provides a more linear relationship. This is a common relationship in hydrology and is often used to estimate rainfall in ungauged basins. However, once the data is transformed, the lack of spread in the streamflow data is quite evident with high mean flow values being compressed to the low end of aridity/high end of rainfall.

To address this, we can visualize how a log transform may benifit the q_mean data as well. Since the data is represented by color, rather then an axis, we can use the trans (transform) argument in the scale_color_viridis_c() function to log transform the color scale.

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  # Apply a log transformation to the color scale
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        # Expand the legend width ...
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```

Treating these three right skewed variables as log transformed, we can see a more evenly spread relationship between aridity, rainfall, and mean flow. This is a good sign for building a model to predict mean flow using aridity and rainfall.

## Model Building

First, we set a seed for reproducabilty, then transform the q_mean column to a log scale. It is error prone to apply transformations to the outcome variable within a recipe. So, we’ll do it a prioi.

Once set, we can split the data into a training and testing set. We are going to use 80% of the data for training and 20% for testing with no stratification.

Additionally, we are going to create a 10-fold cross validation dataset to help us evaluate multi-model setups.

```{r}
set.seed(123)
# Bad form to perform simple transformations on the outcome variable within a 
# recipe. So, we'll do it here.
camels <- camels |> 
  mutate(logQmean = log(q_mean))

# Generate the split
camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

Here, we are going to use the recipe function to define a series of data preprocessing steps.

We learned quite a lot about the data in the visual EDA. We know that the q_mean, aridity and p_mean columns are right skewed and can be helped by log transformations. We also know that the relationship between aridity and p_mean is non-linear and can be helped by adding an interaction term to the model. To implement these, lets build a recipe.

```{r}
# Create a recipe to preprocess the data
rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  # Log transform the predictor variables (aridity and p_mean)
  step_log(all_predictors()) %>%
  # Add an interaction term between aridity and p_mean
  step_interact(terms = ~ aridity:p_mean) %>%
  # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes(), skip = TRUE)
```

First, we use prep and bake on the training data to apply the recipe. Then, we fit a linear model to the data.

```{r}
# Prepare the data
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

# Interaction with lm
#  Base lm sets interaction terms with the * symbol
lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```

```{r}
# Sanity Interaction term from recipe ... these should be equal!!
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

To correctly evaluate the model on the test data, we need to apply the same preprocessing steps to the test data that we applied to the training data. We can do this using the prep and bake functions with the recipe object. This ensures the test data is transformed in the same way as the training data before making predictions.

```{r}
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)
```

Now that we have the predicted values, we can evaluate the model using the metrics function from the yardstick package. This function calculates common regression metrics such as RMSE, R-squared, and MAE between the observed and predicted values.

```{r}
metrics(test_data, truth = logQmean, estimate = lm_pred)
```

```{r}
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  # Apply a gradient color scale
  scale_color_gradient2(low = "brown", mid = "orange", high = "darkgreen") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")
```

Workflows are built from a model, a preprocessor, and a execution. Here, we are going to use the linear_reg function to define a linear regression model, set the engine to lm, and the mode to regression. We then add our recipe to the workflow, fit the model to the training data, and extract the model coefficients.

```{r}
# Define model
lm_model <- linear_reg() %>%
  # define the engine
  set_engine("lm") %>%
  # define the mode
  set_mode("regression")

# Instantiate a workflow ...
lm_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(lm_model) %>%
  # Fit the model to the training data
  fit(data = camels_train) 

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients
```

```{r}
# From the base implementation
summary(lm_base)$coefficients
```

Now that lm_wf is a workflow, data is not embedded in the model, we can use augment with the new_data argument to make predictions on the test data.

```{r}
#
lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)
```

As with EDA, applying for graphical and statistical evaluation of the model is a key Here, we use the metrics function to extract the default metrics (rmse, rsq, mae) between the observed and predicted mean streamflow values.

We then create a scatter plot of the observed vs predicted values, colored by aridity, to visualize the model performance.

```{r}
metrics(lm_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

Here, we are going to instead use a random forest model to predict mean streamflow. We define a random forest model using the rand_forest function, set the engine to ranger, and the mode to regression. We then add the recipe, fit the model, and evaluate the skill.

```{r}
library(baguette)
rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(rf_model) %>%
  # Fit the model
  fit(data = camels_train) 
```

Make predictions on the test data using the augment function and the new_data argument.

```{r}
rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)
```

Evaluate the model using the metrics function and create a scatter plot of the observed vs predicted values, colored by aridity.

```{r}
metrics(rf_data, truth = logQmean, estimate = .pred)
```

```{r}
ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

workflow_set is a powerful tool for comparing multiple models on the same data. It allows you to define a set of workflows, fit them to the same data, and evaluate their performance using a common metric. Here, we are going to create a workflow_set object with the linear regression and random forest models, fit them to the training data, and compare their performance using the autoplot and rank_results functions.

```{r}
wf <- workflow_set(list(rec), list(lm_model, rf_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)
```

```{r}
rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

## Question 3

```{r}
library(tidymodels)  
library(glmnet)

#1 Data split & 10‑fold CV
set.seed(123)
camels_split <- initial_split(camels, prop = 0.75, strata = logQmean)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)
camels_cv    <- vfold_cv(camels_train, v = 10, strata = logQmean)

#2 Recipe
rec_flow <- recipe(
  logQmean ~ p_mean + aridity + pet_mean + slope_mean + frac_forest,
  data = camels_train
) %>%
  step_impute_median(all_numeric_predictors()) %>%  
  step_zv(all_numeric_predictors())                 

#3 The four models
rf_mod  <- rand_forest(
             trees = 300,           
             mtry  = tune()         
           ) %>% set_engine("ranger") %>% set_mode("regression")

xgb_mod <- boost_tree(
             trees       = 300,     
             learn_rate  = tune(),  
             tree_depth  = tune()
           ) %>% set_engine("xgboost") %>% set_mode("regression")

glm_mod <- linear_reg(               
             penalty = 0.01,
             mixture = 0.5
           ) %>% set_engine("glmnet")

cart_mod <- decision_tree(           
              cost_complexity = tune(),
              tree_depth      = tune()
            ) %>% set_engine("rpart") %>% set_mode("regression")

models <- list(
  rf   = rf_mod,
  xgb  = xgb_mod,
  glm  = glm_mod,
  cart = cart_mod
)

#4 Workflow set and quick grid search
wf_set <- workflow_set(
  preproc = list(flow = rec_flow),
  models  = models
)

set.seed(456)
wf_res <- wf_set %>%
  workflow_map(
    fn        = "tune_grid",
    resamples = camels_cv,
    grid      = 3,                           
    metrics   = metric_set(rsq, rmse),
    control   = control_grid(verbose = TRUE,
                             save_pred = FALSE)  
  )

#5 Inspect results
autoplot(wf_res)                        
rank_results(wf_res,                   
             rank_metric = "rsq",
             select_best = TRUE)
```

rand_forest is the best model to move forward with, because it has the best RMSE of 0.46, and the best R^2 value of 0.9. It also has the error bars, which means it it more stable across the 10 folds. 

```{r}
library(tidymodels)     
library(glmnet)         
theme_set(theme_bw())   

set.seed(20250516)

#1 Train/test split 75/25
camels_split <- initial_split(camels, prop = 0.75, strata = logQmean)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

#2 10‑fold cross‑validation on training set
camels_cv <- vfold_cv(camels_train, v = 10, strata = logQmean)

rec_flow <- recipe(
  logQmean ~ p_mean + pet_mean + aridity +
             slope_mean + elev_mean +
             frac_snow + frac_forest,
  data = camels_train
) %>%
  step_impute_median(all_numeric_predictors()) %>%   
  step_zv(all_numeric_predictors()) %>%             
  step_YeoJohnson(all_numeric_predictors()) %>%     
  step_normalize(all_numeric_predictors())          

#4 Model 
rf_spec <- rand_forest(mtry = tune(), trees = 400, min_n = tune()) %>%
             set_engine("ranger", importance = "impurity") %>%
             set_mode("regression")

rf_wf <- workflow() %>%
           add_recipe(rec_flow) %>%
           add_model(rf_spec)

#5 Hyper‑parameter search 
set.seed(20250516)
rf_grid <- grid_regular(
  mtry(range = c(3L, 7L)),
  min_n(range = c(2L, 10L)),
  levels = 3            
)

rf_res <- tune_grid(
  rf_wf,
  resamples = camels_cv,
  grid      = rf_grid,
  metrics   = metric_set(rsq, rmse),
  control   = control_grid(verbose = TRUE)
)

#6 Select best 
best_rf <- select_best(rf_res, metric = "rsq")

final_rf <- finalize_workflow(rf_wf, best_rf)

final_fit <- last_fit(final_rf, camels_split)
collect_metrics(final_fit)
```
The model relies on seven physically meaningful basin attributes: p_mean, the long‑term mean precipitation that represents the primary water input; pet_mean, potential evapotranspiration that captures atmospheric water demand; aridity, the P/PET ratio reflecting overall climate stress; slope_mean, average basin steepness that governs how quickly runoff responds to rainfall; elev_mean, mean elevation acting as a proxy for snow storage and temperature gradients; frac_snow, the proportion of precipitation falling as snow, which controls seasonal flow timing; and frac_forest, the fraction of forest cover that influences interception losses and evapotranspiration buffering. Together these variables summarize the key climate, topographic, and land‑cover controls on mean streamflow.



```{r}
rf_mod <- rand_forest(
            mtry  = tune(),     # #predictors to sample at each split
            trees = 400,        # keep runtime reasonable
            min_n = tune()      # min data points in a node
          ) %>% 
          set_engine("ranger", importance = "impurity") %>% 
          set_mode("regression")


xgb_mod <- boost_tree(
             trees       = 300,          
             learn_rate  = tune(),      
             tree_depth  = tune(),     
             min_n       = tune()       
           ) %>% 
           set_engine("xgboost") %>% 
           set_mode("regression")

glmnet_mod <- linear_reg(
                penalty = tune(),  
                mixture = tune()  
              ) %>% 
              set_engine("glmnet")   

```

```{r}
models <- list(rf = rf_mod,
               xgb = xgb_mod,
               glmnet = glmnet_mod)

wf_set <- workflow_set(
  preproc = list(flow = rec_flow),   
  models  = models
)

```

```{r}
set.seed(456)
wf_res <- wf_set %>%
  workflow_map(
    "tune_grid",
    resamples = camels_cv,           
    grid      = 3,                  
    metrics   = metric_set(rsq, rmse),
    control   = control_grid(verbose = TRUE)
  )

```

```{r}
rank_results(wf_res, rank_metric = "rsq", select_best = TRUE)

```
```{r}
models <- list(
  rf     = rf_mod,     
  xgb    = xgb_mod,    
  glmnet = glmnet_mod 
)


wf_set <- workflow_set(
  preproc = list(flow = rec_flow), 
  models  = models                
)


set.seed(456)
wf_res <- wf_set %>%
  workflow_map(
    fn        = "tune_grid",
    resamples = camels_cv,           
    grid      = 3,                  
    metrics   = metric_set(rsq, rmse),
    control   = control_grid(verbose = TRUE,
                             save_pred = FALSE)  
  )


library(dplyr)

rank_results(wf_res, rank_metric = "rsq", select_best = TRUE)


autoplot(wf_res)         

```

The random‑forest model is the strongest choice: it averages R^2 values just above 0.90 and delivers the lowest cross‑validated RMSE (0.45), while also showing the tightest error bars across folds—evidence of both superior accuracy and stability. Boosted trees trail slightly (R^2 = 0.88, RMSE = 0.50) and would need extra tuning to catch up, the elastic‑net GLM underperforms on nonlinear relationships (R^2 = 0.84), and the single CART clearly underfits (R^2 = 0.65). Given its top accuracy, consistency, and built‑in variable‑importance outputs, the tuned random‑forest is the model to move forward with.

```{r}
library(tidymodels); library(ggplot2); library(viridis)


final_rf_wf <- rf_wf %>%               
  finalize_workflow(best_rf)           


final_fit <- fit(final_rf_wf, data = camels_train)


test_pred <- augment(final_fit, new_data = camels_test)  


metric_set(rsq, rmse)(test_pred, truth = logQmean, estimate = .pred)


test_pred <- test_pred %>%
  mutate(resid = .pred - logQmean) 

ggplot(test_pred, aes(logQmean, .pred, colour = abs(resid))) +
  geom_point(alpha = 0.7, size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  scale_colour_viridis_c(option = "plasma", name = "|Residual|") +
  labs(
    title = "Observed vs Predicted logQmean on Test Set (Random‑Forest)",
    x = "Observed logQmean",
    y = "Predicted logQmean"
  ) +
  coord_equal() +
  theme_bw()
```
The points cluster tightly around the 1:1 dashed line, and the test metrics echo CV performance (R^2 = 0.91, RMSE = 0.45). Density shading shows no systemic bias: predictions track low, mid, and high flows with comparable accuracy, though the extreme low‑flow tail widens slightly—expected for a log‑scale target. Overall, the model generalises well to unseen basins and comfortably meets the >0.90 R^2 requirement.
